\documentclass[12pt]{article}
\usepackage{indentfirst}
\usepackage{fullpage}
\usepackage{multicol,multirow}
\usepackage{tabularx}
\usepackage{ulem}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{float}
\usepackage{listings}
\usepackage{color}
\usepackage{hyperref}
\usepackage{graphicx}
\DeclareGraphicsExtensions{.png}
\graphicspath{{pics/}}
\renewcommand{\labelenumii}{\arabic{enumi}.\arabic{enumii}.}

\begin{document}
	\section*{Лабораторная работа №\,2 по курсу ИИ}
	Выполнил студент группы М8О-308Б-17 МАИ \textit{Гринин Вячеслав Витальвич}.
	
	\subsection*{Условие}
	
	Необходимо реализовать алгоритмы машинного обучения. Применить данные алгоритмы на наборы данных, подготовленных в первой лабораторной работе. Провести анализ полученных моделей, вычислить метрики классификатора. Произвести тюнинг параметров в случае необходимости. Сравнить полученные результаты с моделями реализованными в scikit-learn. Аналогично построить метрики классификации. Показать, что полученные модели не переобучились. Также необходимо сделать выводы о применимости данных моделей к вашей задаче.
	
	\subsubsection*{Алгоритмы}
	\begin{enumerate}
	    \item Логистическая регрессия
	    \item KNN
	    \item Дерево решений
	    \item Случайный лес
	\end{enumerate}
	
	\subsection*{Метод решения}
	
	\subsubsection*{Датасеты и постановка задачи}
    
    В процессе предыдущей лабораторной было создано два датасета, а также поставлены задачи машинного обучения:
    \begin{itemize}
        \item RGB - содержится информация о цветах. На её основе надо обучить сеть определять яркость - тусклые и яркие цвета.
        \item Статистика видео на YouTube - содержится {\bf много} различной информации по видео, а также является ли видео популярным или нет. С его помощью надо научить нейросеть определять, является ли ролик популярным или нет.
    \end{itemize}
    
    \subsubsection*{Результаты}
    
    Собственноручные реализации из "грязи и палок"\ оказывались всегда медленее реализаций из модуля {\tt sklearn}. Не знаю, что там с этими алгоримами делали, но явно что-то страшное. Для сравнения реализация KNN из этого модуля полностью отрабатывала за 3 секунды, в то время как местная реализация работала 3 минуты. И именно из-за этой причины мне часто казалось, что что-то идёт не так. Как итог я тратил в пустую время, пока искал возможные ошибки (что было катастрофически пробелмно, потому что я не знал, как в {\tt python} производить отладку аля {\tt C++}).
    
    Бонусом идёт то, что точность также была ниже. Однако в этом случае разница не такая катастрофическая. Теперь к самим алгоритмам.
    
    \begin{enumerate}
        \item Логистическая регрессия - практически быстрее всех. Однако на втором датасете проявила худшую точность. Причиной тому может являться то, что признаки не получилось как-то линейно разделить.
        \item KNN - отработала несколько дольше, но взамен выдала великолепную точность. Особенно проблема по скорости чувствуется в местной реализации.
        \item Дерево решений - самая быстрая и самая точная рука на диком Западе. Данный алгоритм отлично подходит для данных датасетов.
        \item Случайный лес - выдал несколько похуже результаты, чем обычное дерево решений, хоть и идейно случайный лес использует просто несколько деревьев решений.
    \end{enumerate}
	\subsection*{Выводы}
	
	Пришёл к выводу, что писать на Питоне без какой-либо особой подготовки можно, но очень проблематично, потому что большую часть времени тратишь на чтение различной документации.
	
	Что касается самих алгоритмов, каждый из них имеет свои границы применимости, где они будут максимально эффективны. Например, условием хорошей работы логистической регрессии является возможность линейно разделить обучающую выборку. 
	
	Отдельно стоит отметить дерево решений. Он является достаточно универсальным, однако в то же время он имеет неплохие шансы к переобучению. Связано это с тем, что в процессе обучения алгоритм подгоняет свои узлы под выборку, включая шум. Из-за этого он будет достаточно плохо воспринимать новую информацию. Это исправимо, если ограничить его глубину. Но тогда появляется некоторая погрешность, что тоже не очень хорошо. Решением этой проблемы является случайный лес - группировка нескольких деревьев решений в один лес.
	
\end{document}